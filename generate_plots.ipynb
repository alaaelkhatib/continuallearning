{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Generating Plots\n",
    "\n",
    "This notebook shows how to generate accuracy plots.\n",
    "\n",
    "It is intended to be executed after the `train.py` script finishes execution and outputs the logs to the `logs` folder for your experiment.\n",
    "\n",
    "Make sure the `exp_name` and `episode_name` below are set correctly."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from plot import average_repeats, compute_forgetting, plot_forgetting\n",
    "from plot import get_baselines, compute_intransigence, add_switch_pts\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as grd"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Specify experiemnt name and episode as defined in `train.py`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'demo'\n",
    "episode_name = 'c100-2'"
   ]
  },
  {
   "source": [
    "Define some parameters to configure the figures"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_key = {'Vanilla': '-o',\n",
    "         'L2': '-v',\n",
    "         'EWC': '-x',\n",
    "         'RWalk': '-^'}\n",
    "\n",
    "c_key = {'Vanilla': 'orchid',\n",
    "         'L2': 'lightskyblue',\n",
    "         'EWC': 'lightcoral',\n",
    "         'RWalk': 'limegreen'}"
   ]
  },
  {
   "source": [
    "These paths should correspond to the log files generated after running `train.py`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = {\n",
    "    episode_name : {\n",
    "        'baseline': Path('logs') / exp_name / 'baselines' / episode_name,\n",
    "        'Vanilla': Path('logs') / exp_name / 'vanilla' / episode_name / 'main',\n",
    "        'L2': Path('logs') / exp_name / 'l2' / episode_name / 'main',\n",
    "        'EWC': Path('logs') / exp_name / 'ewc' / episode_name / 'main',\n",
    "        'RWalk': Path('logs') / exp_name / 'rwalk' / episode_name / 'main'\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "source": [
    "Generate the accuracy plot."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fontsize = 12\n",
    "plt.figure(figsize=(8, 8))\n",
    "bmetrics, _, _ = average_repeats(trials[episode_name]['baseline'])\n",
    "bacc = get_baselines(bmetrics)\n",
    "\n",
    "for key, fname in trials[episode_name].items():\n",
    "    if key == 'baseline':\n",
    "        continue\n",
    "    metrics, mxs, spts = average_repeats(fname)\n",
    "    forgetting = compute_forgetting(metrics, mxs)\n",
    "\n",
    "    plt.plot(*zip(*metrics['T0-avg-MH']), p_key[key],\n",
    "                    label=key, markevery=6, color=c_key[key])\n",
    "\n",
    "add_switch_pts(spts)\n",
    "plt.xlabel('Batches seen', fontsize=fontsize)\n",
    "plt.ylabel('Accuracy', fontsize=fontsize)\n",
    "plt.ylim([0.5, 1.])\n",
    "\n",
    "plt.legend(loc='upper center', fontsize=fontsize)"
   ]
  }
 ]
}